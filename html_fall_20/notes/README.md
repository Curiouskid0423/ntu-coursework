# Notes on ML Foundation / Technique :rocket: 

## Course Notes

- Learn more about **Theory of Generalization**   ([Lec22](https://www.youtube.com/watch?v=rUFqB5Z3YHQ&list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf&index=22) - [Lec25](https://www.youtube.com/watch?v=rUFqB5Z3YHQ&list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf&index=22)). Especially the "sketch of proof" of **VC bound**.
- In PLA where sign (WX) = Y, if X input is "linearly dependent", Y cannot be shattered. Reasoning [here](https://youtu.be/9kra9i6jS1g?t=4440) with proof by contradiction. 

## External Learning Resources
- **UMich** EECS598 Statistical ML [Notes Website](https://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/index.html) (Winter 2014)
    - [VC Theory resources](https://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/notes/05_vc_theory.pdf) from UMich EECS 598 (Winter 2014)

    - [KL divergence and Hoeffding's Inequality](https://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/notes/03_hoeffding.pdf) notes from UMich EECS 598 (Winter 2014)

- **Stanford** CS229 ML [Website](http://cs229.stanford.edu/syllabus-fall2020.html) Fall 2020:
    - [Linear Algebra Reference](http://cs229.stanford.edu/notes2020fall/notes2020fall/linalg2.pdf)
    May be useful when learning Matrix Calculus, or reviewing concepts such as diagonalization.
- **Berkeley** Prof Shewchuk [CS189](https://people.eecs.berkeley.edu/~jrs/189/)
    - ML Foundation / ML Technique is modeled after **Caltech** [Learning from Data](https://work.caltech.edu/telecourse), so the aspect of ML teaching can be quite different from Berkeley.
    - [A Comprehensive ML Guide](http://snasiriany.me/files/ml-book.pdf) and Prof Sahai's lecture notes on [EECS189](https://www.eecs189.org)
    - Should be able to take advantage of some learning resources here already.
- **Caltech** [Machine Learning Video Library](https://work.caltech.edu/library/index.html) (probably more similar to NTU's course) than Berkeley's.